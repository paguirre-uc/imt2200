{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6e2b08",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#173267;\">\n",
    "    <br>\n",
    "    <img src=\"logo-uc-01.svg\" style=\"align:center;width:20%;\">\n",
    "    <p style=\"text-align:center;font-family:Trebuchet MS;color:white;font-size:40pt;font-weight:bold;margin:50px\">\n",
    "        AYUDANTÍA 11\n",
    "    </p>\n",
    "    <p style=\"text-align:center;font-family:Trebuchet MS;color:white;font-size:20pt;font-weight:bold;margin:50px\">\n",
    "        Introducción a la Ciencia de Datos\n",
    "    </p>\n",
    "    <p style=\"text-align:center;font-family:Trebuchet MS;color:white;font-size:12pt;\">\n",
    "        Felipe Gutiérrez - figutier@uc.cl\n",
    "        Nicolas Mendicoa - nmendicoa@uc.cl\n",
    "    </p>\n",
    "    <p style=\"text-align:center;font-family:Trebuchet MS;color:white;font-size:12pt;\">        \n",
    "        Modificado notebook de:\n",
    "        Vicente Agüero - vicenteaguero@uc.cl\n",
    "        <br>27 de Octubre de 2022\n",
    "    </p>\n",
    "    <br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e554068",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:20pt;font-weight:bold;\">\n",
    "    Preliminares\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8874a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.base import BaseEstimator\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d3ae5",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:20pt;font-weight:bold;\">\n",
    "    Datos\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mnist = fetch_openml('mnist_784', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24888b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f68c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnist['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a37146b",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    Fathers of the Deep Learning Revolution Receive ACM A.M. Turing Award 2018\n",
    "    </p>\n",
    "    <img src=\"https://awards.acm.org/binaries/content/gallery/acm/ctas/awards/turing-2018-bengio-hinton-lecun.jpg\" style=\"width:30%;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mnist['data'].loc[0].values.reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist['target'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b55c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colores (tonos de gris) van de 0-255, ¿por qué? 2^8=256 -> 8 bits\n",
    "mnist['data'].loc[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0539eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No necesitamos más colores en realidad... el ojo humano distingue de 1-10 millones de colores (más cercano a 1)\n",
    "255*255*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a0df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist['frame'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65377443",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist['target'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "fig, ax = plt.subplots(n, 3*n, figsize=(30, 15))\n",
    "ax = ax.flatten()\n",
    "for i in range(3*n**2):\n",
    "    ax[i].imshow(mnist['data'].loc[i].values.reshape(28, 28), cmap='gray')\n",
    "    ax[i].axis('off')\n",
    "    ax[i].set_title(mnist['target'].loc[i], fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829535fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist['data']\n",
    "y = mnist['target'].astype(np.uint8)\n",
    "x_train, x_test, y_train, y_test = X[:60000].values, X[60000:].values, y[:60000].values, y[60000:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9eab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb87fb83",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:20pt;font-weight:bold;\">\n",
    "    Clasificación\n",
    "</p>\n",
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    ¿Cuál es la diferencia entre clasificación y regresión?\n",
    "</p>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    En general, tenemos lo siguiente:\n",
    "    $$\\text{Clasificación}\\Rightarrow\\text{Predecir clases};\\ \\text{e.g.}\\ f(X)=Y\\ \\text{con}\\ Y\\in\\{\\text{Gato}, \\text{Perro}\\}$$\n",
    "    $$\\text{Regresión}\\Rightarrow\\text{Predecir valores};\\ \\text{e.g.}\\ f(X)=Y\\ \\text{con}\\ Y\\in[0,1]$$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4725af9c",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:20pt;font-weight:bold;\">\n",
    "    Clasificación KNN\n",
    "</p>\n",
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    K-Nearest-Neighbors (K-Vecinos Cercanos)<br>La idea detrás de KNN es cercanía (¿distancia?)\n",
    "</p>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/Knn_k1_z96jba.png\" style=\"width:40%;\"/>\n",
    "</div>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/KNN_final1_ibdm8a.png\" style=\"width:60%;\"/>\n",
    "</div>\n",
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    ¿Gente Libre o Dothrakis?\n",
    "</p>\n",
    "<table><tr>\n",
    "<td> <img src=\"https://static0.srcdn.com/wordpress/wp-content/uploads/2020/06/Wildlings.jpg?q=50&fit=crop&w=960&h=500&dpr=1.5\" style=\"height:300px;\"/> </td>\n",
    "<td> <img src=\"https://www.hellofriki.com/wp-content/uploads/2017/05/58-780x470.jpg\" style=\"height:300px;\"/> </td>\n",
    "</tr></table>\n",
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    ¿Chihuahua o Muffin?\n",
    "</p>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://cdn-media-1.freecodecamp.org/images/1*bt-E2YcPafjiPbZFDMMmNQ.jpeg\" style=\"width:40%;\"/>\n",
    "</div>\n",
    "<br><br><br>\n",
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:20pt;font-weight:bold;\">\n",
    "    KNN es un algoritmo...\n",
    "</p>\n",
    "<ul style=\"text-align:left;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    <li>Lazy (no Eager).</li>\n",
    "    <li>Instance-based (Memory-based).</li>\n",
    "    <li>Non-parametric.</li>\n",
    "    <li>Fast training.</li>\n",
    "    <li>Multiclass.</li>\n",
    "    <li>Multilabel.</li>\n",
    "    <li>Multioutput.</li>\n",
    "    <li>Muchas métricas (distancia).</li>\n",
    "    <li>Curse of Dimensionality.</li>\n",
    "    <li>Costoso en Complejidad Computacional.</li>\n",
    "</ul>\n",
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:20pt;font-weight:bold;\">\n",
    "    KNN es hoy en día utilizado en...\n",
    "</p>\n",
    "<ul style=\"text-align:left;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    <li>Sistemas Recomendadores.</li>\n",
    "    <li>Documentos similares.</li>\n",
    "    <li>Detección de outliers.</li>\n",
    "    <li>Etcétera$\\dots$ (fraudes, troubleshooting, spam, Amazon,$\\dots$).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué hiperpárametros tiene KNN?\n",
    "#help(KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae29844",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99693d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(x_train, np.where(y_train == 9, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d15cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predicted = knn.predict(x_test)\n",
    "expected = np.where(y_test == 9, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0662ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(predicted, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(expected, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(predicted, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c641fd",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:20pt;font-weight:bold;\">\n",
    "    Clasificación de MNIST (dígitos 0-9) con KKN\n",
    "</p>\n",
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    ¡Random!\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7438c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.random.randint(0, 10, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clf = RandomClassifier()\n",
    "random_clf.fit(x_train, y_train)\n",
    "predicted = random_clf.predict(x_test)\n",
    "expected = y_test\n",
    "np.unique(predicted, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(predicted, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb87bb0",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    KNN para clasificar desde 0 a 9\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e3657",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0828354",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predicted = knn.predict(x_test)\n",
    "expected = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90df5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(predicted, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e355bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(expected, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a56150",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(predicted, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d930d",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:20pt;font-weight:bold;\">\n",
    "    Métricas de Clasificación.\n",
    "</p>\n",
    "<p style=\"text-align:center;font-family:Arial;color:#fe001a;font-size:15pt;font-weight:bold;\">\n",
    "    ADVENTENCIA: ¡EL ORDEN IMPORTA EN SKLEARN.METRICS!<br>(Expected, Predicted) o ($y_{\\text{true}}, y_{\\text{pred}})$\n",
    "</p>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    Todos los modelos deberían tener una métrica interna accesible seguro (al menos en sklearn). Se utiliza llamando al método <i>score</i> de la instancia del modelo.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b9a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2631cd3",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    <b>Esta métrica no nos va a interesar mucho.</b> En realidad, en la práctica, no se utiliza. En el caso anterior, vemos que es igual al <i>accuracy</i>. Sin embargo, ¿quién nos garantiza que esto siempre sea así para todos los modelos? ¿Cómo la podré comparar entonces? ¿Casos multi-label? ¿Casos multi-output? ¿Y si tengo 20 modelos diferentes? Métrica muy básica, con poca información y me pide correr todo otra vez.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d537d5f9",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    <b>Matriz de Confusión</b>\n",
    "</p>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    La matriz de confusión nos indica la cantidad de veces que una variable $A$ fue clasificada como $B$ (caso binario) o la cantidad de veces que una variable $A_i$ fue clasificada como $A_j$ con $i=0,\\dots,n$, $j=0,\\dots,n$ y $n$ la cantidad de labels (caso multi-label). Donde idealmente, lo que buscamos es clasificar siempre $A$ como $A$ o $A_i$ como $A_i\\ \\forall i$ (modelo perfecto).\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 9\n",
    "confusion_matrix(expected == l, predicted == l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd59a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(expected, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(expected == 9, predicted == 9, ax=ax, cmap='Blues')\n",
    "ax.set_title('Confusion Matrix Binary\\n(Classification of 9)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ConfusionMatrixDisplay.from_predictions(expected, predicted, ax=ax, cmap='Blues')\n",
    "ax.set_title('Confusion Matrix Multiclass')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebec3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "cm = ConfusionMatrixDisplay.from_predictions(expected, predicted, ax=ax, cmap='Blues', normalize='pred')\n",
    "ax.set_title('Confusion Matrix Multiclass\\n(Prediction normalized)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d21909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "cm = ConfusionMatrixDisplay((confusion_matrix(expected, predicted)/np.unique(predicted, return_counts=True)[1])*100).plot(ax=ax, cmap='Blues')\n",
    "ax.set_title('Confusion Matrix Multiclass\\n(Prediction normalized in %)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d93b89",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    <b>Accuracy Score</b>\n",
    "</p>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    Esta métrica nos dice el ratio de cuántas veces la predicción ($\\hat{y}$) fue hecha correctamente (pasar a porcentaje $\\texttt{accuracy}*100%$).\n",
    "    <br><br>\n",
    "    <b>En otras palabras:</b> ¿qué tanto le achunté?\n",
    "    <br><br>\n",
    "    $$\\texttt{accuracy}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples}-1} \\mathbb{1}_{(\\hat{y}_i = y_i)}$$\n",
    "    $$\\mathbb{1}_{y}(\\hat{y})=\n",
    "    \\begin{cases} \n",
    "        0 & \\hat{y}\\neq y \\\\\n",
    "        1 & \\hat{y}= y\n",
    "    \\end{cases}\n",
    "    $$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(expected, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al mirar la fórmula podemos ver que acá el orden no importa....\n",
    "accuracy_score(predicted, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(predicted == expected).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3971a5",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    <b>Precision Score</b>\n",
    "</p>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    <b>Aclaración:</b> Está en inglés, por eso no dice Precisión. De hecho, a traducción correcta sería: <i>accuracy</i> es precisión y <i>precision</i> es exactitud.\n",
    "    <br><br>\n",
    "    Esta métrica nos dice el ratio de los verdaderos positivos ($tp$) entre la suma de los verdaderos positivos y los falsos positivos ($fp$).\n",
    "    <br><br>\n",
    "    <b>En otras palabras:</b> Tengo mi clasificador para el número $9$, cuando predigo que SÍ es un $9$... ¿qué tanto le achunté?\n",
    "    <br><br>\n",
    "    $$\\texttt{precision} = \\frac{tp}{tp + fp}$$\n",
    "    <br>\n",
    "    ¿Positivo y Negativo? Eso es como medio binario... ¡exactamente!\n",
    "    <br><br>\n",
    "    $$\\texttt{precision}=\\texttt{precision}_{\\text{binary}}$$\n",
    "    <br>\n",
    "    Hay que cambiar la interpretación de cómo calculamos el <i>precision score</i> para más de un label.\n",
    "    <br><br>\n",
    "    $$\\texttt{precision}_{\\text{macro}}=\\frac{1}{\\left|L\\right|} \\sum_{l \\in L} P(y_l, \\hat{y}_l)$$\n",
    "    $$\\texttt{precision}_{\\text{weighted}}=\\frac{1}{\\sum_{l \\in L} \\left|\\hat{y}_l\\right|} \\sum_{l \\in L} \\left|\\hat{y}_l\\right| P(y_l, \\hat{y}_l)$$\n",
    "    <br>\n",
    "    Ojo, $l$ es un label del conjunto $L$ de labels. Generalmente, la notación $|L|$ se le llama la cardinalidad del conjunto $L$ (cantidad de elementos en $L$).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e515eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average = {‘micro’, ‘macro’, ‘samples’, ‘weighted’, ‘binary’, None}, default='binary'.\n",
    "l = 9\n",
    "precision_score(expected == l, predicted == l, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df7efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al mirar la fórmula podemos ver que acá el orden SÍ importa....\n",
    "precision_score(predicted == l, expected == l, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c06d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp, tp = np.unique(expected[predicted == l] == l, return_counts=True)[1]\n",
    "tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c331a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(expected, predicted, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(10):\n",
    "    fp, tp = np.unique(expected[predicted == l] == l, return_counts=True)[1]\n",
    "    print(f'l={l}; precision={(tp / (tp + fp)):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ec0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(predicted, expected, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(predicted, expected, average=None).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db2d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average = {‘micro’, ‘macro’, ‘samples’, ‘weighted’, ‘binary’, None}\n",
    "precision_score(predicted, expected, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(precision_score(predicted, expected, average=None) * np.unique(predicted, return_counts=True)[1]).sum() / np.unique(predicted, return_counts=True)[1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156e9733",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    <b>Ejemplo de $\\texttt{precision}_{\\text{weighted}}$ muy útil:</b> Clasificación $L=\\{\\text{Perro},\\text{Gato}\\}$. Mi estimador dijo $1000$ veces $\\hat{y}=\\text{Perro}$ con $P=100%$ y $100$ veces dijo que era $\\hat{y}=\\text{Gato}$ con $P=75%$. Por lo que<br><br>$$|\\hat{y}_\\text{Perro}|=1000\\ \\ \\text{y}\\ \\ |\\hat{y}_\\text{Gato}|=100$$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b96d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precisión_macro = {(1+0.75)/2}')\n",
    "print(f'Precisión_weighted = {(1000*1+100*0.75)/(1000+100)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428fa87d",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    <b>Recall Score</b>\n",
    "</p>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    Esta métrica nos dice el ratio de los verdaderos positivos ($tp$) entre la suma de los verdaderos positivos y los falsos negativos ($fn$).\n",
    "    <br><br>\n",
    "    <b>En otras palabras:</b> Tengo mi clasificador para el número $9$, cuando mi predicción correcta debería ser SÍ es un $9$ ¿qué tanto le achunté? Esta es mi habilidad de identificación del $9$, que no se me escape el $9$.\n",
    "    <br><br>\n",
    "    $$\\texttt{recall}_{\\text{binary}} = \\frac{tp}{tp + fn}$$\n",
    "    <br>\n",
    "    $$\\texttt{recall}_{\\text{macro}}=\\frac{1}{\\left|L\\right|} \\sum_{l \\in L} R(y_l, \\hat{y}_l)$$\n",
    "    $$\\texttt{recall}_{\\text{weighted}}=\\frac{1}{\\sum_{l \\in L} \\left|\\hat{y}_l\\right|} \\sum_{l \\in L} \\left|\\hat{y}_l\\right| R(y_l, \\hat{y}_l)$$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3837c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average = {‘micro’, ‘macro’, ‘samples’, ‘weighted’, ‘binary’, None}, default='binary'.\n",
    "l = 9\n",
    "recall_score(expected == l, predicted == l, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb77e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(expected, predicted, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(expected, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(expected, predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd9406b",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    <b>F1 Score</b><br>(F$_\\beta$ score con $\\beta=1$, también llamado F-score)\n",
    "</p>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    Esta métrica nos dice la media armónica ($H$) entre el precision y el recall. Donde la media armónica es el recíproco de la media aritmética ($\\bar{x}$) de los recíprocos.\n",
    "    <br><br>\n",
    "    $$H=\\frac{n}{\\sum\\limits_{i=1}^n \\frac{1}{x_i}}=\\left(\\frac{\\sum\\limits_{i=1}^n x_i^{-1}}{n}\\right)^{-1}\\ \\ \\text{y} \\ \\ \\bar{x}=\\frac{\\sum\\limits_{i=1}^n x_i}{n}$$\n",
    "    <br>\n",
    "    <b>En otras palabras:</b> Tengo mi clasificador para el número $9$, cuando digo que es 9 y cuando digo que no es 9, ¿qué tanto le achunto? Es decir, identificar correctamente números diferentes al $9$ y que no me pase que digo que es $9$ y estoy equivocado.\n",
    "    <br><br>\n",
    "    $$\\texttt{F1} = 2\\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}}$$\n",
    "    <br>\n",
    "    $$\\texttt{F1}_{\\text{macro}}=\\frac{1}{\\left|L\\right|} \\sum_{l \\in L} F1(y_l, \\hat{y}_l)$$\n",
    "    $$\\texttt{F1}_{\\text{weighted}}=\\frac{1}{\\sum_{l \\in L} \\left|\\hat{y}_l\\right|} \\sum_{l \\in L} \\left|\\hat{y}_l\\right| F1(y_l, \\hat{y}_l)$$\n",
    "    <br><br><br>\n",
    "</p>\n",
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    <b>F$_\\beta$ score</b>\n",
    "</p>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    Esta métrica nos dice la media armónica ponderada entre el precision y el recall.\n",
    "    <br><br>\n",
    "    <b>En otras palabras:</b> Tengo mi clasificador para el número $9$, cuando digo que es 9 y cuando digo que no es 9, siendo una de estas más importantes, ¿qué tanto le achunto? Es decir, identificar correctamente números diferentes al $9$ y que no me pase que digo que es $9$ y estoy equivocado, sin embargo, ambos problemas no son igual de importantes.\n",
    "    <br><br>\n",
    "    $$\\texttt{F}_\\beta = (1 + \\beta^2) \\frac{\\text{precision} \\times \\text{recall}}{\\beta^2 \\text{precision} + \\text{recall}}$$\n",
    "    <br>\n",
    "    $$\\texttt{F}_{\\beta_{\\text{macro}}}=\\frac{1}{\\left|L\\right|} \\sum_{l \\in L} F_\\beta(y_l, \\hat{y}_l)$$\n",
    "    $$\\texttt{F}_{\\beta_{\\text{weighted}}}=\\frac{1}{\\sum_{l \\in L} \\left|\\hat{y}_l\\right|} \\sum_{l \\in L} \\left|\\hat{y}_l\\right| F_\\beta(y_l, \\hat{y}_l)$$\n",
    "    ¿Qué es más importante para ustedes?\n",
    "    $$\\texttt{precision}\\ \\text{más importante que el}\\ \\texttt{recall}\\ \\Rightarrow\\ \\beta<1\\ \\ \\ \\ (\\text{si}\\ b\\to0\\ \\text{solo importa el}\\ \\texttt{precision})$$\n",
    "    $$\\texttt{precision}\\ \\text{menos importante que el}\\ \\texttt{recall}\\ \\Rightarrow\\ \\beta>1\\ \\ \\ \\ (\\text{si}\\ b\\to \\infty\\ \\text{solo importa el}\\ \\texttt{recall})$$\n",
    "    $$\\texttt{precision}\\ \\text{igual de importante que el}\\ \\texttt{recall}\\ \\Rightarrow\\ \\beta=1$$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average = {‘micro’, ‘macro’, ‘samples’, ‘weighted’, ‘binary’, None}, default='binary'.\n",
    "l = 9\n",
    "f1_score(expected == l, predicted == l, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(expected, predicted, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510086dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(expected, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(expected, predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average = {‘micro’, ‘macro’, ‘samples’, ‘weighted’, ‘binary’, None}, default='binary'.\n",
    "fbeta_score(expected, predicted, beta=1, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79df268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average = {‘micro’, ‘macro’, ‘samples’, ‘weighted’, ‘binary’, None}, default='binary'.\n",
    "fbeta_score(expected, predicted, beta=2, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aadb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbeta_score(expected, predicted, beta=0.5, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda2685",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:15pt;font-weight:normal;\">\n",
    "    <b>Classification Report</b>\n",
    "</p>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    ¡Viva las métricas! Nos entrega el $\\texttt{accuracy}$, $\\texttt{precision}$, $\\texttt{recall}$, $\\texttt{f1}$ y el soporte ($|y_l|\\ \\text{con}\\ l\\in L$) en las versiones <i>binary</i>, <i>macro</i> y <i>weighted</i> de los <i>scores</i>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existe una versión llamada \"precision_recall_fscore_support\" que es similar pero con funcionalidades distintas (más personalizado, ej: elegir beta para F_beta).\n",
    "print(classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e309280",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:20pt;font-weight:bold;\">\n",
    "    Cross-Validation\n",
    "</p>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    Técnica de muestreo para hacer que nuestro modelo sea eficiente y preciso para datos que NO ha visto.\n",
    "    <br><br>\n",
    "    Se basa en dividir nuestros datos en entrentrenamiento y testeo muchas veces, testear el rendmiento de estas nuevas particiones y luego, juntamos todo otra vez.\n",
    "    <br><br>\n",
    "    Es mucho mejor que solo dividir según un porcentaje (train_test_split), previene el overfitting y el underfitting. \n",
    "</p>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://miro.medium.com/max/305/1*nk0514O3cRWid25TKn7IIA.png\" style=\"width:20%;\"/>\n",
    "</div>\n",
    "<br><br><br>\n",
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:20pt;font-weight:bold;\">\n",
    "    Leave-one-out Cross-Validation\n",
    "</p>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    Básicamente, testeamos con un dato y entrenamos con el resto. Esto lo hacemos para cada dato.\n",
    "</p>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://miro.medium.com/max/556/1*qx1UY2yM4Vn4N4kEg8mqzA.png\" style=\"width:50%;\"/>\n",
    "</div>\n",
    "<br><br>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://miro.medium.com/max/300/1*26vyRHpqGbVAwJq_csUqZQ.gif\" style=\"width:30%;\"/>\n",
    "</div>\n",
    "<br><br>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    Por obvias razones, esto es muy costoso. Sus aplicaciones son más bien apreciadas en técnicas estadísticas, bayesianas, modelos no parámetricos bayesianos, etc.\n",
    "</p>\n",
    "<br><br><br>\n",
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:20pt;font-weight:bold;\">\n",
    "    K-Fold Cross-Validation\n",
    "</p>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    Dividimos nuestros datos en $K$ particiones, donde vamos rotando la partición que usaremos para el test. Así, estamos testeando mucho más el comportamiento de nuestros entrenamiento frente a datos no vistos (unseen data).\n",
    "</p>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://miro.medium.com/max/537/1*AckPZznvp6gAb9XyaIMytQ.png\" style=\"width:50%;\"/>\n",
    "</div>\n",
    "<br><br>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://miro.medium.com/max/350/1*2rRcNnIokzJU_-NXm29IMA.gif\" style=\"width:30%;\"/>\n",
    "</div>\n",
    "<br><br>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    <b>Pros:</b> Previene que datos outliers afecten mucho, menor costo computacional que otros CV (LOO-CV).\n",
    "    <br><br>\n",
    "    <b>Contras:</b> Datos imbalanced, unbalanced o no balanceados (no hay la misma cantidad de datos en cada fold).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb9501",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "CV = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "knnCV = dict()\n",
    "predCV = np.zeros(5)\n",
    "k = 0\n",
    "# ¡Tomé solo una muestra por el tiempo!\n",
    "n_sample = 10000\n",
    "for train_i, test_i in CV.split(x_train[:n_sample], y_train[:n_sample]):\n",
    "    k += 1\n",
    "    knnCV[k] = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean', n_jobs=-1)\n",
    "    x_train_fold = x_train[train_i]\n",
    "    y_train_fold = y_train[train_i]\n",
    "    x_test_fold = x_train[test_i]\n",
    "    y_test_fold = y_train[test_i]\n",
    "    knnCV[k].fit(x_train_fold, y_train_fold)\n",
    "    pred_fold = knnCV[k].predict(x_test_fold)\n",
    "    predCV[k-1] = f1_score(y_test_fold, pred_fold, average='weighted')\n",
    "    print(f'K={k}; F1-score={predCV[k-1]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80840d73",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-family:Arial;color:#173267;font-size:20pt;font-weight:bold;\">\n",
    "    Stratified K-Fold Cross-Validation\n",
    "</p>\n",
    "<p style=\"text-align:justify;font-family:Arial;color:#173267;font-size:12pt;font-weight:normal;\">\n",
    "    Igual que K-Fold CV pero todas las clases tienen la misma cantidad de datos. Lo que previene trabajar con datos mal balanceados (muchísimos modelos manejas muy mal datasets no balanceados).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "SCV = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "knnSCV = dict()\n",
    "predSCV = np.zeros(5)\n",
    "k = 0\n",
    "# ¡Tomé solo una muestra por el tiempo!\n",
    "n_sample = 10000\n",
    "for train_i, test_i in SCV.split(x_train[:n_sample], y_train[:n_sample]):\n",
    "    k += 1\n",
    "    knnSCV[k] = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean', n_jobs=-1)\n",
    "    x_train_fold = x_train[train_i]\n",
    "    y_train_fold = y_train[train_i]\n",
    "    x_test_fold = x_train[test_i]\n",
    "    y_test_fold = y_train[test_i]\n",
    "    knnSCV[k].fit(x_train_fold, y_train_fold)\n",
    "    pred_fold = knnSCV[k].predict(x_test_fold)\n",
    "    predSCV[k-1] = f1_score(y_test_fold, pred_fold, average='weighted')\n",
    "    print(f'K={k}; F1-score={predSCV[k-1]}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
